---

### ğŸ“˜ **Structure du rapport (5 Ã  10 pages)**

#### **1. Introduction** *(1/2 page Ã  1 page)*
- PrÃ©sentation du projet.
- Objectif : entraÃ®ner une voiture Ã  naviguer sur un circuit grÃ¢ce au reinforcement learning.
- Outils utilisÃ©s : Godot + Godot-RL.
- Plan du rapport.

#### **2. ThÃ©orie du Reinforcement Learning (RL)** *(1 Ã  2 pages)*
- DÃ©finition du RL.
- Concepts fondamentaux :
  - Agent, Environnement, Ã‰tat, Action, RÃ©compense.
  - Politique, Fonction de valeur (V), Q-Learning, Exploration vs Exploitation.
- Algorithmes possibles utilisÃ©s par la librairie (DQN, PPO, etc.).
- Pourquoi le RL est adaptÃ© Ã  ce problÃ¨me.

> âœ… **TÃ¢che pour 1 personne** : rÃ©diger la partie thÃ©orique avec schÃ©ma explicatif simple si possible.

#### **3. PrÃ©sentation de Godot & Godot-RL** *(1 Ã  1.5 page)*
- Introduction Ã  Godot :
  - Moteur de jeu open-source, systÃ¨me de scÃ¨nes/nÅ“uds.
  - Pourquoi il est adaptÃ© Ã  ce projet (2D/3D lÃ©ger, open).
- Mise en place de lâ€™environnement :
  - Comment on a modÃ©lisÃ© le circuit, les capteurs de la voiture.
  - Interaction entre Godot et Godot-RL.
- PrÃ©sentation de la librairie [Godot-RL](https://github.com/edbeeching/godot_rl_agents) :
  - Communication via sockets.
  - Environnement â†’ Observation â†’ Action â†’ Reward.

> âœ… **TÃ¢che pour 1 personne** : expliquer lâ€™aspect technique de la mise en place de lâ€™environnement.

#### **4. EntraÃ®nement de lâ€™agent** *(1 Ã  2 pages)*
- Configuration de l'entraÃ®nement :
  - Type de capteurs (lidar, raycasts, etc.), observation space, reward function.
  - HyperparamÃ¨tres utilisÃ©s (learning rate, epsilon, etc.).
- MÃ©thode dâ€™apprentissage utilisÃ©e (ex : PPO).
- Courbe dâ€™Ã©volution de lâ€™apprentissage si possible.

> âœ… Ã€ partager avec celui qui s'occupe de la partie test.

#### **5. Tests effectuÃ©s et retours dâ€™expÃ©rience** *(2 Ã  3 pages)*
- Tests rÃ©ussis :
  - Description de la configuration, rÃ©sultats obtenus, comportement de lâ€™agent.
- Tests Ã©chouÃ©s :
  - Ce qui a Ã©tÃ© tentÃ©, pourquoi Ã§a a Ã©chouÃ© (ex : reward mal dÃ©finie, overfitting, mauvais sensors).
  - Comment vous avez corrigÃ© ou ce que vous avez appris.
- Comparaison de diffÃ©rents rÃ©glages.

> âœ… **TÃ¢che pour 1 personne** : documenter les essais/erreurs, captures dâ€™Ã©cran utiles ici.

#### **6. Conclusion & Perspectives** *(1 page)*
- RÃ©sumÃ© des rÃ©sultats.
- Limites rencontrÃ©es.
- IdÃ©es dâ€™amÃ©liorations (ex : multi-agents, meilleure perception, circuits plus complexes).
- Ce que vous avez appris sur le RL, Godot, et le travail en Ã©quipe.

---

### âœ… **Conseils supplÃ©mentaires**

- Faites attention Ã  la clartÃ© des schÃ©mas : mÃªme un dessin simple du cycle RL ou de lâ€™agent dans le circuit peut rendre votre rapport plus pro.
- Mentionnez les versions des outils utilisÃ©s.
- Si possible, ajoutez une **annexe** avec du code ou des logs.

---
